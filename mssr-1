import os
from glob import glob
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Show image function
def show_image(tensor, title="Image"):
    tensor = tensor.cpu().detach()
    image = tensor.permute(1, 2, 0).numpy()  # Convert from (C, H, W) to (H, W, C)
    image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0,1]
    plt.imshow(image)
    plt.title(title)
    plt.axis('off')
    plt.show()

#############################################
# PART 1: IMAGE PATCH EXTRACTION FROM GoPro DATASET
#############################################

# Parameters for patch extraction
patch_size = 256  # training on 256x256 patches
src = 'GOPRO_Large/train'  # Raw dataset location

# Get image file paths (using sorted() instead of natsort)
lr_files = sorted(glob(os.path.join(src, '*', 'blur', '*.png')) + 
                  glob(os.path.join(src, '*', 'blur', '*.jpg')))
hr_files = sorted(glob(os.path.join(src, '*', 'sharp', '*.png')) + 
                  glob(os.path.join(src, '*', 'sharp', '*.jpg')))

# Load one image pair for demonstration
lr_image_path = lr_files[0]
hr_image_path = hr_files[0]

# Open images using PIL
lr_image = Image.open(lr_image_path)
hr_image = Image.open(hr_image_path)

# Convert to RGB if needed
lr_image = lr_image.convert('RGB')
hr_image = hr_image.convert('RGB')

# Convert PIL images to torch tensors
lr_tensor = torch.tensor(np.array(lr_image).transpose((2, 0, 1)), dtype=torch.float32).unsqueeze(0) / 255.0
hr_tensor = torch.tensor(np.array(hr_image).transpose((2, 0, 1)), dtype=torch.float32).unsqueeze(0) / 255.0

# Define model (using the same model you provided)
class SpatialRearrangementUnit(nn.Module):
    def __init__(self, window_size):
        super(SpatialRearrangementUnit, self).__init__()
        self.window_size = window_size
        self.step = window_size // 2

    def rearrange_dimension(self, x, dim):
        chunk_size = self.window_size // 2
        chunks = list(x.split(chunk_size, dim=dim))
        num_chunks = (x.size(dim) - 2 * chunk_size) // chunk_size
        num_groups = num_chunks // 2
        new_chunks = []
        for i in range(1, num_groups + 1):
            first = chunks[2 * i - 2]
            second = chunks[2 * i + 1]
            new_chunks.append(torch.cat([first, second], dim=dim))
        return torch.cat(new_chunks, dim=dim)

    def forward(self, x):
        B, C, H, W = x.shape
        chunk_size = self.window_size // 2

        left_pad = x[:, :, :, :chunk_size]
        right_pad = x[:, :, :, -chunk_size:]
        x_padded_w = torch.cat([left_pad, x, right_pad], dim=3)
        x_width = self.rearrange_dimension(x_padded_w, dim=3)

        top_pad = x_width[:, :, :chunk_size, :]
        bottom_pad = x_width[:, :, -chunk_size:, :]
        x_padded_h = torch.cat([top_pad, x_width, bottom_pad], dim=2)
        x_final = self.rearrange_dimension(x_padded_h, dim=2)
        return x_final

class MultiscaleSRM(nn.Module):
    def __init__(self, in_channels, hidden_dim, out_channels, patch_size):
        super(MultiscaleSRM, self).__init__()
        self.patch_size = patch_size

        self.sru_small = SpatialRearrangementUnit(window_size=2)
        self.sru_medium = SpatialRearrangementUnit(window_size=4)
        self.sru_large = SpatialRearrangementUnit(window_size=8)

        flattened_dim = in_channels * patch_size * patch_size
        self.mlp = nn.Sequential(
            nn.Linear(flattened_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, flattened_dim)
        )

    def forward(self, x):
        x_small = self.sru_small(x)
        x_medium = self.sru_medium(x)
        x_large = self.sru_large(x)
        
        x_combined = x_small + x_medium + x_large
        
        B, C, H, W = x_combined.shape
        flattened = x_combined.view(B, -1)
        
        restored = self.mlp(flattened)
        restored = restored.view(B, C, H, W)
        return restored

#############################################
# PART 2: TESTING THE MODEL WITH A PATCH
#############################################
def test_model():
    # Load image as a dummy patch for testing
    model = MultiscaleSRM(in_channels=3, hidden_dim=64, out_channels=3, patch_size=patch_size)
    
    # Forward pass through the model to restore the image
    output = model(lr_tensor)  # Pass the blurry image through the model
    
    # Show images using show_image function
    show_image(lr_tensor[0], title="Blurry Image")  # Show the original blurry image
    show_image(output[0], title="Restored Image")  # Show the restored image

test_model()
