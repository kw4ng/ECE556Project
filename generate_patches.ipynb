{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5861df0-dee2-4d40-b156-b3caa879c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (8.4.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "## Reference: https://github.com/vztu/maxim-pytorch/blob/main/Deblurring/generate_patches_gopro.py \n",
    "\n",
    "##### Data preparation file for training Restormer on the GoPro Dataset ########\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "!pip install natsort\n",
    "from natsort import natsorted\n",
    "import os\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "# !pip install pdb\n",
    "from pdb import set_trace as stx\n",
    "!pip install joblib\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def train_files(file_):\n",
    "    lr_file, hr_file = file_\n",
    "    filename = os.path.splitext(os.path.split(lr_file)[-1])[0]\n",
    "    lr_img = cv2.imread(lr_file)\n",
    "    hr_img = cv2.imread(hr_file)\n",
    "    num_patch = 0\n",
    "    w, h = lr_img.shape[:2]\n",
    "    if w > p_max and h > p_max:\n",
    "        w1 = list(np.arange(0, w-patch_size, patch_size-overlap, dtype=int))\n",
    "        h1 = list(np.arange(0, h-patch_size, patch_size-overlap, dtype=int))\n",
    "        w1.append(w-patch_size)\n",
    "        h1.append(h-patch_size)\n",
    "        for i in w1:\n",
    "            for j in h1:\n",
    "                num_patch += 1\n",
    "                \n",
    "                lr_patch = lr_img[i:i+patch_size, j:j+patch_size,:]\n",
    "                hr_patch = hr_img[i:i+patch_size, j:j+patch_size,:]\n",
    "                \n",
    "                lr_savename = os.path.join(lr_tar, filename + '-' + str(num_patch) + '.png')\n",
    "                hr_savename = os.path.join(hr_tar, filename + '-' + str(num_patch) + '.png')\n",
    "                \n",
    "                cv2.imwrite(lr_savename, lr_patch)\n",
    "                cv2.imwrite(hr_savename, hr_patch)\n",
    "\n",
    "    else:\n",
    "        lr_savename = os.path.join(lr_tar, filename + '.png')\n",
    "        hr_savename = os.path.join(hr_tar, filename + '.png')\n",
    "        \n",
    "        cv2.imwrite(lr_savename, lr_img)\n",
    "        cv2.imwrite(hr_savename, hr_img)\n",
    "\n",
    "def val_files(file_):\n",
    "    lr_file, hr_file = file_\n",
    "    filename = os.path.splitext(os.path.split(lr_file)[-1])[0]\n",
    "    lr_img = cv2.imread(lr_file)\n",
    "    hr_img = cv2.imread(hr_file)\n",
    "\n",
    "    lr_savename = os.path.join(lr_tar, filename + '.png')\n",
    "    hr_savename = os.path.join(hr_tar, filename + '.png')\n",
    "\n",
    "    w, h = lr_img.shape[:2]\n",
    "\n",
    "    i = (w-val_patch_size)//2\n",
    "    j = (h-val_patch_size)//2\n",
    "                \n",
    "    lr_patch = lr_img[i:i+val_patch_size, j:j+val_patch_size,:]\n",
    "    hr_patch = hr_img[i:i+val_patch_size, j:j+val_patch_size,:]\n",
    "\n",
    "    cv2.imwrite(lr_savename, lr_patch)\n",
    "    cv2.imwrite(hr_savename, hr_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e1ec8-c320-489a-af2e-b4c0be5a72c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2103 blurry images\n",
      "Found 2103 sharp images\n",
      "Prepared 2103 image pairs\n",
      "First image pair:\n",
      "  LR: GOPRO_Large/train/GOPR0372_07_00/blur/000047.png\n",
      "  HR: GOPRO_Large/train/GOPR0372_07_00/sharp/000047.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████▉          | 1620/2103 [01:19<00:26, 18.29it/s]"
     ]
    }
   ],
   "source": [
    "############ Prepare Training data ####################\n",
    "num_cores = 10\n",
    "patch_size = 256 # training on 256 * 256 patches\n",
    "overlap = 128\n",
    "p_max = 0\n",
    "\n",
    "src = 'GOPRO_Large/train' # raw dataset location\n",
    "tar = 'Datasets/train/GoPro' # cropped dataset new location\n",
    "\n",
    "lr_tar = os.path.join(tar, 'input_crops') # blurry cropped picture\n",
    "hr_tar = os.path.join(tar, 'target_crops') # sharp cropped corresponding picture\n",
    "\n",
    "os.makedirs(lr_tar, exist_ok=True)\n",
    "os.makedirs(hr_tar, exist_ok=True)\n",
    "\n",
    "# Get images from the files, since we did not download via their python code we need to add '*' bc /input/scene../images \n",
    "# instead of directly /input/images\n",
    "lr_files = natsorted(glob(os.path.join(src, '*', 'blur', '*.png')) + glob(os.path.join(src, '*', 'blur', '*.jpg')))\n",
    "hr_files = natsorted(glob(os.path.join(src, '*', 'sharp', '*.png')) + glob(os.path.join(src, '*', 'sharp', '*.jpg')))\n",
    "\n",
    "# Confirm Path correct?\n",
    "files = [(i, j) for i, j in zip(lr_files, hr_files)] # pair up blurrry and sharp images\n",
    "print(f\"Found {len(lr_files)} blurry images\")\n",
    "print(f\"Found {len(hr_files)} sharp images\")\n",
    "print(f\"Prepared {len(files)} image pairs\")\n",
    "# Validate pairing correct?\n",
    "if len(files) > 0:\n",
    "    print(f\"First image pair:\\n  LR: {files[0][0]}\\n  HR: {files[0][1]}\") \n",
    "    \n",
    "# actual cropping\n",
    "Parallel(n_jobs=num_cores)(delayed(train_files)(file_) for file_ in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58deec10-880d-4a40-900f-18d1589c97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Prepare validation data ####################\n",
    "val_patch_size = 256\n",
    "src = 'GOPRO_Large/test'\n",
    "tar = 'Datasets/val/GoPro'\n",
    "\n",
    "lr_tar = os.path.join(tar, 'input_crops')\n",
    "hr_tar = os.path.join(tar, 'target_crops')\n",
    "\n",
    "os.makedirs(lr_tar, exist_ok=True)\n",
    "os.makedirs(hr_tar, exist_ok=True)\n",
    "\n",
    "lr_files = natsorted(glob(os.path.join(src, '*', 'blur', '*.png')) + glob(os.path.join(src, '*', 'blur', '*.jpg')))\n",
    "hr_files = natsorted(glob(os.path.join(src, '*', 'sharp', '*.png')) + glob(os.path.join(src, '*', 'sharp', '*.jpg')))\n",
    "\n",
    "files = [(i, j) for i, j in zip(lr_files, hr_files)]\n",
    "\n",
    "Parallel(n_jobs=num_cores)(delayed(val_files)(file_) for file_ in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732f4d5-7248-480e-bfdf-4a25363350d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
